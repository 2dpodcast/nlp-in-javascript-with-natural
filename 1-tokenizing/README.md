# Break up language strings into parts using Natural 

We will learn about “tokenizing,” the process of separating strings into parts. We will run through the four tokenizers included in Natural: WordTokenizer, WordPunctTokenizer, TreebankWordTokenizer, and RegexpTokenizer.